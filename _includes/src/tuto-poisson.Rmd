---
title: "Tutoriel régression de Poisson"
author: "Matthieu Doutreligne"
date: "8 novembre 2018"
output: 
  html_document:
    toc: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

On s'intéresse aux différentes formes de régression que l'on peut utiliser lorsque l'on fait une régresion glm (generalized linear model) avec R (ou SAS). Pourquoi utiliser un modèle de poisson plutôt qu'un modèle gaussien ? Qu'est ce que cela change ? Dans quel cas utiliser l'un plutôt que l'autre ? Et si je fais de la classification et non pas une regression ?

Chargement des packages
```{r, warning =F}
library(sandwich)
library(msm)
# pour les graphes
library(ggplot2)
# pour les couleurs
library(RColorBrewer)
mypalette = RColorBrewer::brewer.pal( 8, "Set1")
```

## Un exemple avec le nombre de prix obtenus par des élèves

### Exploration du dataset exemple

Ce dataset comporte une ligne par élève et s'intéresse à prédire (et expliquer) le nombre de prix, *num_awards* obtenus par chaque élève selon 2 paramètres: 

  + Son programme scolaire, *prog* 
  + Sa notation en mathématiques, *math* 

```{r}
# chargement de la table depuis le site de l'université
p =read.csv("https://stats.idre.ucla.edu/stat/data/poisson_sim.csv")

p =within(p, {
  # redéfinit les facteurs (valeurs prises par variable catégorielle) pour la variable prog
  prog =factor(prog, levels=1:3, labels=c("General", "Academic", "Vocational"))
  id =factor(id)
})

summary(p)
# Nombre d'indivus
N = length(p$id)
N
```

Les élèves se répartissent dans plusieurs programmes:

```{r}
ggplot(p, aes(num_awards, fill = prog)) +
  geom_histogram(binwidth=.5, position="dodge")
```

Et on peut visualiser la distribution de leurs notes en mathématiques:
```{r}
ggplot() + geom_density(aes(p$math), col = mypalette[2]) + xlab("math")
```

Ou bien leur nombre de prix en prenant en compte leur programme et leurs notes en mathématiques:
```{r}
ggplot() +  geom_point(aes(x = p$math, y = p$num_awards, colour = p$prog))
```

Les données ne sont donc pas compliquées du tout à comprendre. Lorsqu'on a des bonnes notes en maths et qu'on est dans le programme on reçoit des prix. Pas de chance pour les littéraires et les sportifs! 

On va utiliser ce dataset jouet pour essayer de mettre en évidence les différences entre les différents modèles.

## Différentes méthodes de regression

### Régression gaussienne 

Le modèle le plus courant est celui de la regression linéraire gaussienne.

Ici, le modèle d'erreur est gaussien. La formule mathématique pour cette régression est:
$$\mathbb E[y|x] = \theta^T x + \epsilon$$ avec $\epsilon \sim \mathcal N(0, \sigma^2)$

On suppose ici, que le nombre de prix reçu par un élève suit une loi gaussienne dont la moyenne $\mu$ est linéraire en les paramètres $\theta$ et les caractéristiques de chaque élève $x = (prog, score)$ 

On estime les paramètres $\theta$ par ordinary least square et $\sigma$ par son estimation empirique (corrigée par le nombre de paramètres pour être non-biaisée): $\hat\sigma^2 = \frac{\sum_{i=1}^N (y_i - \hat y_i)^2}{N - p - 1}$ où les $\hat y_i$ sont les valeures prédites par le modèle.

**NOTA:** Dans GLM (l'algo d'optimisation des modèles linéraires généralisés implémenté sur R et sur SAS), l'algorithme utilisé est plus fin que OLS. Il gère tous les modèles de la [famille exponentielle](https://en.wikipedia.org/wiki/Exponential_family) et se nomme **Iteratively Reweighted Least Square** (et revient à OLS pour le modèle gaussien) -> cf.([IRLS](https://en.wikipedia.org/wiki/Iteratively_reweighted_least_squares) pour plus de détail sur l'algorithme).


Cet algorithme d'optimisation repose sur la forme du modèle pour les itérations et changera donc la valeur des paramètres obtenus in fine selon qu'on utilise un modèle gaussien ou bien de Poisson.

Si l'on se représente ceci avec une regression univariée (notée $\mathbb E [y|math] = a \cdot math+ b $ ou en notation R $y \sim math$), on suppose que le nombre de prix de l'élèves est une gaussienne de moyenne $\mu_{eleve} a \cdot math + b$. 

Visuellement, cela donne:

```{r}
m_simp = glm(num_awards  ~ math, family = "gaussian", data = p)
summary(m_simp)
```

```{r}
# nombre de paramètres utilisés par le modèle
nb_pars = length(m_simp$coefficients) - 1
b = m_simp$coefficients[1]
a = m_simp$coefficients[2]
y_pred = a*p$math + b
# on peut obtenir directement y_pred avec m_simp$fitted.values
# modele gaussien, erreur estimée:
## estimateur non biaisé de l'erreur standard \sigma (notons que celui obtenu par le glm n'est pas unbiased, c'est seulement sd(m_simp$residuals))
sigma_hat = sd(m_simp$residuals) * N/ (N- nb_pars - 1)
xx_g = seq(-5,5, 0.1)
yy_g = dnorm(xx_g, mean = 0, sd =sigma_hat)
# modele de poisson, erreur estimée:

#tt = summary(m_simp)
## On se place en un point test:
x_test = 50
y_test = predict(object = m_simp, newdata = data.frame("math" = x_test))
# valeurs prédites
ggplot() + geom_line(aes(x = p$math, y = y_pred, colour = "Predicted values")) + 
  # vraies valeurs
  geom_point(aes(x = p$math, y = p$num_awards, colour = "True values"))  + 
  # point test
  geom_point(aes(x_test, y_test)) + 
  # erreur au point test
  geom_polygon(aes(yy_g*10 + x_test, xx_g + y_test), fill = mypalette[3], alpha = 0.7) +
  ylim(-3,6)
```

Si l'on refait la même chose pour le modèle entier:

```{r}
m_gauss = glm(num_awards ~ prog + math, family="gaussian", data=p)
summary(m_gauss)
```

```{r, echo =F}
# nombre de paramètres utilisés par le modèle
nb_pars = length(m_gauss$coefficients) - 1
b = m_gauss$coefficients[1]
a = m_gauss$coefficients[2]
y_pred = m_gauss$fitted.values
# modele gaussien, erreur estimée:
## estimateur non biaisé de l'erreur standard \sigma
sigma_hat = sd(m_gauss$residuals) * N/ (N- nb_pars - 1)
xx_g = seq(-5,5, 0.1)
yy_g = dnorm(xx_g, mean = 0, sd =sigma_hat)
# modele de poisson, erreur estimée:

#tt = summary(m_gauss)
## On se place en un point test:
x_test = data.frame("math" = 50 , "prog" = "Academic")
y_test = predict(object = m_gauss, newdata = x_test)
# valeurs prédites
ggplot() + geom_point(aes(x = p$math, y = y_pred, colour = "Predicted values")) + 
  # vraies valeurs
  geom_point(aes(x = p$math, y = p$num_awards, colour = "True values"))  + 
  # point test
  geom_point(aes(x_test$math, y_test)) + 
  # erreur au point test
  geom_polygon(aes(yy_g*10 + x_test$math, xx_g + y_test), fill = mypalette[3], alpha = 0.7) +
  ylim(-3,6)
```


On voit que le modèle qui a été fitté a pris en compte l'information sur les programmes avec un terme fixe rajouté pour chaque programme. Cela donne donc trois droites de même pente et un décalage dû au programme suivi par l'élève. 


Première remarque sur le modèle gaussien:
On remarque que l'erreur gaussienne n'est pas vraiment adaptée aux données de comptage car le bruit est réparti de manière gaussienne autour des points de données, ce qui n'a pas de sens pour des données discrètes.


#### Avec un terme d'interaction

Ici l'idée est que les effets d'une variable peuvent varier selon les valeurs d'un autre coefficients. Typiquement avoir une bonne note en maths n'a pas le même effet selon qu'on est dans le programme General que si l'on est dans le programme Academic. L'interaction se rajoute à volonté entre des variables dans les glm. 

Elle correspond à une nouvelle variable ajoutée au modèle linéaire qui revient mathématiquement à  la multiplaction d'un dummy sur la variable catégorielle (*prog* = General)  avec la variable *math* . On peut interpréter le coefficient *progAcademic:math*  comme l'influence de la note en maths sachant le programme.

Pour deux variables x_1 (continue) et x_2 (prenant les valeurs 0 ou 1) la différence dans la formule mathématique est la suivante:
  Sans intéraction:
  $$\hat y = x_0 + x_1\theta_1 + x_2\theta_2$$
Avec interaction
$$\hat y = x_0 + x_1\theta_1 + (x_2== 0)x_1\theta_2 + (x_2 == 1)x_1 \theta_3$$

```{r}
m_gauss_inter = glm(num_awards ~ prog + math + prog:math, family="gaussian", data=p)
summary(m_gauss_inter)
```

```{r, echo = F}
# nombre de paramètres utilisés par le modèle
nb_pars = length(m_gauss_inter$coefficients) - 1
b = m_gauss_inter$coefficients[1]
a = m_gauss_inter$coefficients[2]
y_pred = m_gauss_inter$fitted.values
# modele gaussien, erreur estimée:
## estimateur non biaisé de l'erreur standard \sigma
sigma_hat = sd(m_gauss_inter$residuals) * N/ (N- nb_pars - 1)
xx_g = seq(-5,5, 0.1)
yy_g = dnorm(xx_g, mean = 0, sd =sigma_hat)
# modele de poisson, erreur estimée:

#tt = summary(m_gauss_inter)
## On se place en un point test:
x_test = data.frame("math" = 50 , "prog" = "Academic")
y_test = predict(object = m_gauss_inter, newdata = x_test)
# valeurs prédites
ggplot() + geom_point(aes(x = p$math, y = y_pred, colour = "Predicted values")) + 
  # vraies valeurs
  geom_point(aes(x = p$math, y = p$num_awards, colour = "True values"))  + 
  # point test
  geom_point(aes(x_test$math, y_test)) + 
  # erreur au point test
  geom_polygon(aes(yy_g*10 + x_test$math, xx_g + y_test), fill = mypalette[3], alpha = 0.7) +
  ylim(-3,6)

```

Pour notre cas d'étude, cela a pour impact de créer une droite de pente différente pour chaque programme.

### Régression de Poisson

Le modèle de poisson est formulée de la manière suivante:
$$\mathbb E [y|x] = exp(\theta^Tx)$$ 
Où l'on suppose que y suit une distribution de Poisson de moyenne $\lambda = \mathbb E [y|x] = exp(\theta^Tx)$
Donc la distribution de y sachant x et theta est donnée par $p(y|x; \theta) = \frac{\lambda ^y}{y!}e^{-y}$
Le logiciel de stats résout ceci en cherchant le maximum de vraissemblance (soit avec des méthodes de gradient, soit avec IRLS pour glm)

```{r}
m_poiss = glm(num_awards ~ prog + math, family="poisson", data=p)
summary(m_poiss)
```

Visuellement, voilà ce que ça donne. La distribution sur le point test est discrète et est donc représentée par des carrés verts transparents. Encore une fois ce qu'on représente en tant que predicted values n'est que la moyenne de la loi de poisson de chaque individu. Il serait plus judicieux de faire un tirage de poisson pour chaque individu afin de montrer ce que prédit réellement le modèle. (cf. partie suivante)

```{r, echo = F}
# nombre de paramètres utilisés par le modèle
nb_pars = length(m_poiss$coefficients) - 1
y_pred = m_poiss$fitted.values

## On se place en un point test:
x_test = data.frame("math" = 70 , "prog" = "Academic")
y_test = predict(object = m_poiss, newdata = x_test)

# valeurs prédites
xx_g = seq(0,6, 1)
yy_g = dpois(xx_g, lambda = exp(y_test))
# modele de poisson, erreur estimée:
ggplot() + geom_point(aes(x = p$math, y = y_pred, colour = "Predicted values")) + 
  # vraies valeurs
  geom_point(aes(x = p$math, y = p$num_awards, colour = "True values"))  + 
  # point test
  geom_point(aes(x_test$math, exp(y_test))) + 
  # erreur au point test
  geom_point(aes(yy_g*10 + x_test$math, xx_g), color = mypalette[3], alpha = 0.6, size = 4, shape = 15) +
  geom_vline(xintercept = x_test$math, color = mypalette[3], alpha = 0.6)
  ylim(-0.5,6)

```

On remarque que le modèle d'erreur est déjà bien plus pertinent que dans le modèle Gaussien, on est bien plus convaincu par la distribution des erreurs.


## Comparaison des modèles: 

La comparison de modèles aussi différents est délicat.
En général on s'appuit sur le [AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion) qui est une version ajustée de la log-vraissemblance: 
$$AIC = 2k - log(L)$$ avec L, la vraissemblance donnée par $L =  \prod_{i=1}^n p(y|x;\theta)$ dont la forme varie selon la distribution de probabilité p spécifiée par le modèle.

La valeur de la vraissemblance dépend donc du modèle stochastique (gaussien, poisson, autre..), des données et des paramètres obtenus après avoir entraîné (fitté) le modèle.

**Plus ce critère est bas plus le modèle est adapté aux données**. En effet on cherche un modèle avec une haute vraissemblance (donc une basse Negative Log Likelihood) et le moins de paramètre possible. 

Pour nos différents modèles ce paramètre est donné dans le summary mais peut-être récupéré directement:
```{r}
m_gauss$aic
```
Si l'on compare les différents modèles on voit que celui de poisson semble bien plus adapté ! 

  - Gaussien univarié: AIC = `r m_simp$aic`
  - Gaussien complet: AIC = `r m_gauss$aic`
  - Poisson: AIC = `r m_poiss$aic`

On peut également effectuer un test statistique pour savoir si un modèle est meilleur qu'un autre, c'est ce qu'on appelle le [Likelihood ratio test](https://en.wikipedia.org/wiki/Likelihood-ratio_test) 

Personnellement, je suis faché avec les tests statistiques qui cache de l'information dans la p-valeur donc je préfère regarder les AIC en face des yeux.


### Prédictions avec les lois de distributions des modèles

Ici on regarde comment le modèle prédit les données en tirant des variables suivant le modèle spécifié et de paramètres ceux obtenus par regression:

#### Gaussien

On simule des gaussiennes de moyenne fitted_values et de dispersion sigma_hat

```{r, echo = F}
# nombre de paramètres utilisés par le modèle
nb_pars = length(m_gauss$coefficients) - 1
b = m_gauss$coefficients[1]
a = m_gauss$coefficients[2]
y_pred = m_gauss$fitted.values
# modele gaussien, erreur estimée:
## estimateur non biaisé de l'erreur standard \sigma
sigma_hat = sd(m_gauss$residuals) * N/ (N- nb_pars - 1)
xx_simule = m_gauss$data
yy_simule = rnorm(N, mean =y_pred, sd =sigma_hat)

xx_correct = p$math[abs(yy_simule - p$num_awards)<0.1]
yy_correct = yy_simule[abs(yy_simule - p$num_awards)<0.1]
# valeurs prédites
ggplot() + # vraies valeurs
  geom_point(aes(x = p$math, y = p$num_awards, colour = "True values"), alpha = 0.7, lwd = 3)  +
  geom_point(aes(x = p$math, y = yy_simule, colour = "Wrong simulated values"), lwd = 2) + 
  geom_point(aes(x = xx_correct, y = yy_correct, colour = "Correct simulated values"), lwd = 2) +
  ylim(-3,6) + scale_color_manual(values= c(mypalette[3], mypalette[2], mypalette[1]))
```

#### Poisson
On simule des poissons de moyenne fitted_values
```{r, echo = F}
# nombre de paramètres utilisés par le modèle
nb_pars = length(m_gauss$coefficients) - 1
b = m_poiss$coefficients[1]
a = m_poiss$coefficients[2]
y_pred = m_poiss$fitted.values
# modele gaussien, erreur estimée:
## estimateur non biaisé de l'erreur standard \sigma
sigma_hat = sd(m_poiss$residuals) * N/ (N- nb_pars - 1)
xx_simule = m_poiss$data
yy_simule = rpois(N, lambda =y_pred)
# modele de poisson, erreur estimée:
xx_correct = p$math[yy_simule == p$num_awards]
yy_correct = yy_simule[yy_simule == p$num_awards]
# valeurs prédites
ggplot() + # vraies valeurs
  geom_point(aes(x = p$math, y = p$num_awards, colour = "True values"), alpha = 0.7, lwd = 3)  +
  geom_point(aes(x = p$math, y = yy_simule, colour = "Wrong simulated values"), lwd = 2) + 
  geom_point(aes(x = xx_correct, y = yy_correct, colour = "Correct simulated values"), lwd = 2) +
  ylim(-3,6) + scale_color_manual(values= c(mypalette[3], mypalette[2], mypalette[1]))
  
```

```{r}
# x = seq(length(mypalette))
# y = seq(length(mypalette))
# ggplot() + geom_point(aes(x, 0), col = mypalette, lwd = 5)
```

## Robust standard errors

Robust standard errors comme conseillé par Cameron and Trivedi (2009): 
On peut contrôler pour une légère violation de l'hypothèse selon laquelle la distribution a une variance égale à sa moyenne. On utilise pour cela le package `sandwich` afin d'obtenir les erreurs standards robustes et de calculer les p-values correspondantes. 

```{r}
cov.m_poiss =vcovHC(m_poiss, type="HC0")
std.err = sqrt(diag(cov.m_poiss))
# On regroupe les coeffficients les robusts std errors, les p-values et les intervalles de confiances dans une seule table de résultats
r.est =cbind(Estimate= coef(m_poiss), 
               "Robust SE" = std.err,
               "Pr(>|z|)" = 2 * pnorm(abs(coef(m_poiss)/std.err), lower.tail=FALSE),
               "LL" = coef(m_poiss) - 1.96 * std.err,
               "UL" = coef(m_poiss) + 1.96 * std.err)

r.est
```


## Et la Classification

Une autre fois

## Plus de détails ? 

D'autres modèles de comtpage plus fins sont aussi utilisés:
- Negative binomial (permet de se libérer de l'hypothèse de variance et de moyenne égales de la loi de poisson)
- Zero-inflated regression model pour tenir compte de cas où il y a une sur-représentation de zeros (par exemple pour l'étude de séquençage ADN)

Le lien suivant est un excellent cours sur la théorie derrière les Generalized Linear Models et leur implémentation dans la plupart des logiciels de statistiques (dont R et SAS il me semble): https://data.princeton.edu/wws509/notes/a2.pdf

J'ai allégrement pillé le [post de UCLA ](https://stats.idre.ucla.edu/r/dae/poisson-regression/) (university of California Los Angeles) pour ce tutoriel. Libre à vous d'aller le regarder pour plus de détail. 
